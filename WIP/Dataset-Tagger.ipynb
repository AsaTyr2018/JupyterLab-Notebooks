{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaab14-a6af-4fd2-8ca9-ab1d6bae1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Remove COLAB check and set root_dir to local directory\n",
    "root_dir = \"C:\\jupyterlab\\content\\drive\\lora\"\n",
    "deps_dir = os.path.join(root_dir, \"deps\")\n",
    "\n",
    "project_name = \"ProjectName\" # Enter your project name here\n",
    "project_name = project_name.strip()\n",
    "\n",
    "folder_structure = \"Organize by project (Lora/project_name/dataset)\" # Choose your folder structure\n",
    "\n",
    "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n",
    "  print(\"Please write a valid project_name.\")\n",
    "else:\n",
    "  project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\"/\")]\n",
    "  project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n",
    "\n",
    "  if \"/Loras\" in folder_structure:\n",
    "    main_dir      = root_dir\n",
    "    config_folder = os.path.join(main_dir, project_base)\n",
    "    images_folder = os.path.join(main_dir, project_base, \"dataset\")\n",
    "    if \"/\" in project_name:\n",
    "      images_folder = os.path.join(images_folder, project_subfolder)\n",
    "  else:\n",
    "    main_dir      = root_dir\n",
    "    config_folder = os.path.join(main_dir, \"config\", project_name)\n",
    "    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
    "\n",
    "  for dir in [main_dir, deps_dir, images_folder, config_folder]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "  print(f\"‚úÖ Project {project_name} is ready!\")\n",
    "  step1_installed_flag = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280e0a5-34a3-4fc9-a275-b6bdbf7c094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"step1_installed_flag\" not in globals():\n",
    "  raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "method = \"Anime tags\" \n",
    "tag_threshold = 0.35 \n",
    "blacklist_tags = \"virtual youtuber, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color\"\n",
    "caption_min = 10 \n",
    "caption_max = 75 \n",
    "\n",
    "os.chdir(root_dir)\n",
    "kohya = \"kohya-trainer\"\n",
    "if not os.path.exists(kohya):\n",
    "  os.system('git clone https://github.com/kohya-ss/sd-scripts kohya-trainer')\n",
    "  os.chdir(kohya)\n",
    "  os.system('git reset --hard 5050971ac687dca70ba0486a583d283e8ae324e2')\n",
    "  os.chdir(root_dir)\n",
    "\n",
    "if \"tags\" in method:\n",
    "  if \"step4a_installed_flag\" not in globals():\n",
    "    print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "    os.system('pip install tensorflow==2.12.0 huggingface-hub==0.12.0 accelerate==0.15.0 transformers==4.26.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6 torchvision albumentations')\n",
    "    step4a_installed_flag = True\n",
    "\n",
    "  print(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
    "\n",
    "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "  os.system(f'python {kohya}/finetune/tag_images_by_wd14_tagger.py {images_folder} --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 --model_dir={root_dir} --thresh={tag_threshold} --batch_size=8 --caption_extension=.txt --force_download')\n",
    "\n",
    "  print(\"removing underscores and blacklist...\")\n",
    "  blacklisted_tags = [t.strip() for t in blacklist_tags.split(\",\")]\n",
    "  from collections import Counter\n",
    "  top_tags = Counter()\n",
    "  for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
    "    with open(os.path.join(images_folder, txt), 'r') as f:\n",
    "      tags = [t.strip() for t in f.read().split(\",\")]\n",
    "      tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
    "      tags = [t for t in tags if t not in blacklisted_tags]\n",
    "    top_tags.update(tags)\n",
    "    with open(os.path.join(images_folder, txt), 'w') as f:\n",
    "      f.write(\", \".join(tags))\n",
    "\n",
    "  print(f\"üìä Tagging complete. Here are the top 50 tags in your dataset:\")\n",
    "  print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
    "\n",
    "else: # Photos\n",
    "  if \"step4b_installed_flag\" not in globals():\n",
    "    print(\"\\nüè≠ Installing dependencies...\\n\")\n",
    "    os.system('pip install timm==0.6.12 fairscale==0.4.13 transformers==4.26.0 requests==2.28.2 accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6')\n",
    "    step4b_installed_flag = True\n",
    "\n",
    "  print(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
    "\n",
    "  os.chdir(kohya)\n",
    "  os.system(f'python {kohya}/finetune/make_captions.py {images_folder} --beam_search --max_data_loader_n_workers=2 --batch_size=8 --min_length={caption_min} --max_length={caption_max} --caption_extension=.txt')\n",
    "\n",
    "  import random\n",
    "  captions = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n",
    "  sample = []\n",
    "  for txt in random.sample(captions, min(10, len(captions))):\n",
    "    with open(os.path.join(images_folder, txt), 'r') as f:\n",
    "      sample.append(f.read())\n",
    "\n",
    "  os.chdir(root_dir)\n",
    "  print(f\"üìä Captioning complete. Here are {len(sample)} example captions from your dataset:\")\n",
    "  print(\"\".join(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936bd33-21e7-4447-b884-f75b4b745259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"step1_installed_flag\" not in globals():\n",
    "  raise Exception(\"Please run step 1 first!\")\n",
    "\n",
    "#@markdown ### 5Ô∏è‚É£ Curate your tags\n",
    "#@markdown Modify your dataset's tags. You can run this cell multiple times with different parameters. <p>\n",
    "\n",
    "#@markdown Put an activation tag at the start of every text file. This is useful to make learning better and activate your Lora easier. Set `keep_tokens` to 1 when training.<p>\n",
    "#@markdown Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.\n",
    "global_activation_tag = \"\" #@param {type:\"string\"}\n",
    "remove_tags = \"\" #@param {type:\"string\"}\n",
    "#@markdown &nbsp;\n",
    "\n",
    "#@markdown In this advanced section, you can search text files containing matching tags, and replace them with less/more/different tags. If you select the checkbox below, any extra tags will be put at the start of the file, letting you assign different activation tags to different parts of your dataset. Still, you may want a more advanced tool for this.\n",
    "search_tags = \"\" #@param {type:\"string\"}\n",
    "replace_with = \"\" #@param {type:\"string\"}\n",
    "search_mode = \"OR\" #@param [\"OR\", \"AND\"]\n",
    "new_becomes_activation_tag = False #@param {type:\"boolean\"}\n",
    "#@markdown These may be useful sometimes. Will remove existing activation tags, be careful.\n",
    "sort_alphabetically = False #@param {type:\"boolean\"}\n",
    "remove_duplicates = False #@param {type:\"boolean\"}\n",
    "\n",
    "def split_tags(tagstr):\n",
    "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
    "\n",
    "activation_tag_list = split_tags(global_activation_tag)\n",
    "remove_tags_list = split_tags(remove_tags)\n",
    "search_tags_list = split_tags(search_tags)\n",
    "replace_with_list = split_tags(replace_with)\n",
    "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
    "\n",
    "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
    "replace_new_list.reverse()\n",
    "activation_tag_list.reverse()\n",
    "\n",
    "remove_count = 0\n",
    "replace_count = 0\n",
    "\n",
    "for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
    "\n",
    "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
    "    tags = [s.strip() for s in f.read().split(\",\")]\n",
    "\n",
    "  if remove_duplicates:\n",
    "    tags = list(set(tags))\n",
    "  if sort_alphabetically:\n",
    "    tags.sort()\n",
    "\n",
    "  for rem in remove_tags_list:\n",
    "    if rem in tags:\n",
    "      remove_count += 1\n",
    "      tags.remove(rem)\n",
    "\n",
    "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
    "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
    "    replace_count += 1\n",
    "    for rem in search_tags_list:\n",
    "      if rem in tags:\n",
    "        tags.remove(rem)\n",
    "    for add in replace_with_list:\n",
    "      if add not in tags:\n",
    "        tags.append(add)\n",
    "    for new in replace_new_list:\n",
    "      if new_becomes_activation_tag:\n",
    "        if new in tags:\n",
    "          tags.remove(new)\n",
    "        tags.insert(0, new)\n",
    "      else:\n",
    "        if new not in tags:\n",
    "          tags.append(new)\n",
    "\n",
    "  for act in activation_tag_list:\n",
    "    if act in tags:\n",
    "      tags.remove(act)\n",
    "    tags.insert(0, act)\n",
    "\n",
    "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
    "    f.write(\", \".join(tags))\n",
    "\n",
    "if global_activation_tag:\n",
    "  print(f\"\\nüìé Applied new activation tag(s): {', '.join(activation_tag_list)}\")\n",
    "if remove_tags:\n",
    "  print(f\"\\nüöÆ Removed {remove_count} tags.\")\n",
    "if search_tags:\n",
    "  print(f\"\\nüí´ Replaced in {replace_count} files.\")\n",
    "print(\"\\n‚úÖ Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da124f01-afd8-4951-b954-de666ec307a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
